# Working with CNN Deep Learning Architectures
## This project aims to train, test and plot the performance curves for several CNN architectures on both the MNIST and CIFAR-10 datasets. The following are the four CNN architectures to be implemented:

Design a CNN with:

One Convolution layer which uses 32 kernels each of size 5x5, stride = 1, and padding =0.
One Pooling layer which uses MAXPOOLING with stride =2.
One hidden layer having number of neurons = 100.
Note: Use ReLU activation function after each convolution layer.

Design a CNN with:

Two back-to-back Convolution layers which uses 32 kernels each of size 3x3, stride = 1, and padding =0.
One Pooling layer which uses MAXPOOLING with stride =2.
One hidden layer having number of neurons = 100.
Note: Use ReLU activation function after each convolution layer.

Design the LeNet-5 architecture.

Compare the performances of the above three architectures with respect to the two datasets.

The results will be reported in the form of performance curves and the models will be evaluated based on their accuracy.
